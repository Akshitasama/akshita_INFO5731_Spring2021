{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA and LSA. The following information should be reported:\n",
        "\n",
        "(1) Features (top n-gram phrases) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VlrZJx2rNiJ"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"Reviews.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpFXo3G7sIYe",
        "outputId": "6ed9101e-9f22-46b8-b6c3-17d0afaf07f9"
      },
      "source": [
        "!pip install stop_words"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp37-none-any.whl size=32917 sha256=445dfcd1b56c266b8b4eb27dfd6d6cb24580aa5f2f0e5fea2efd959e0f157cee\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AbcjrTDsLjv"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from stop_words import get_stop_words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "en_st = get_stop_words('en')\n",
        "p_stemmer_ = PorterStemmer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE0bWDwxsZ-z"
      },
      "source": [
        "data['Lower Case'] = data['Review'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "data['Tokenization'] = data['Lower Case'].apply(lambda x: tokenizer.tokenize(x))\n",
        "data['Tokens'] = data['Tokenization'].apply(lambda x: [i for i in x if not i in en_st])\n",
        "data['Stemming'] = data['Tokens'].apply(lambda x: [p_stemmer_.stem(i) for i in x])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZLKm0cPslOK"
      },
      "source": [
        "text_ = []\n",
        "for row in data['Stemming']:\n",
        "  text_.append(line)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Fmvz-rx2m4"
      },
      "source": [
        "**Bigrams and Trigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9jSaQQ9stO8",
        "outputId": "67eccb93-d7b8-4bdb-d547-e90a9a45154f"
      },
      "source": [
        "from gensim import corpora, models\n",
        "bi_gram = models.Phrases(text_, min_count=5, threshold=100)\n",
        "tri_gram = models.Phrases(bi_gram[text_], threshold=100)\n",
        "bi_gram_mod = models.phrases.Phraser(bi_gram)\n",
        "tri_gram_mod = models.phrases.Phraser(tri_gram)\n",
        "print(tri_gram_mod[bi_gram_mod[text_[0]]])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wow', 'movi', 'admit', 'first', 'heard', 'joaquin', 'phoenix', 'go', 'joker', 'surpris', 'wasn', 't', 'sure', 'go', 'pull', 'hope', 'wasn', 't', 'go', 'anoth', 'cheesi', 'rendit', 'full', 'fluff', 'unrealist', 'explan', 'joker', 'came', 'one', 'adult', 'son', 'wouldn', 't', 'keep', 'nudg', 'wake', 'pleasantli', 'surpris', 'well', 'todd', 'phillip', 'version', 'play', 'joaquin', 's', 'act', 'superb', 'feel', 'anguish', 'charact', 'go', 'right', 'point', 'lost', 'mind', 'just', 'excel', 'well', 'act', 'movi', 'almost', 'forget', 'deriv', 'dc', 'comic']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IhK5oihtHJL"
      },
      "source": [
        "def make_bi_grams(text_):\n",
        "    return [bi_gram_mod[doc] for doc in text_]\n",
        "  \n",
        "def make_tri_grams(text_):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in text_]\n",
        "\n",
        "def lemmatization(text_, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    text_out = []\n",
        "    for sent in text_:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        text_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return text_out"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBdAl_TOuCsa",
        "outputId": "74c7a3d4-0a5c-4b00-c256-aeb941f559c8"
      },
      "source": [
        "import spacy\n",
        "data_words_bi_grams = make_bi_grams(text_)\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "data_lemmatized_ = lemmatization(data_words_bi_grams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "print(data_lemmatized_[:1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['admit', 'first', 'hear', 'go', 'sure', 'go', 'pull', 't', 'go', 'anoth', 'cheesi', 'rendit', 'full', 'fluff', 'unrealist', 'come', 'adult', 'son', 'keep', 'nudg', 'wake', 'pleasantli', 'version', 'play', 'feel', 'anguish', 'charact', 'go', 'right', 'point', 'lose', 'mind', 'just', 'almost', 'forget']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcY-TnqJuchU"
      },
      "source": [
        "**Corpus and Dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqiIqeoQuf2O",
        "outputId": "16aa35b5-2086-42a6-ec56-ab0f5bd1ddb8"
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized_)\n",
        "text_ = data_lemmatized_\n",
        "corpus = [id2word.doc2bow(text) for text in text_]\n",
        "print(corpus[:1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 4), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pOVfutisvr7U",
        "outputId": "39a54cdf-dae6-43bd-fdd4-30058949402d"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'admit'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3sVvYm4v0Zn",
        "outputId": "1af5a944-5663-443b-9fc9-8d822aff79cc"
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('admit', 1),\n",
              "  ('adult', 1),\n",
              "  ('almost', 1),\n",
              "  ('anguish', 1),\n",
              "  ('anoth', 1),\n",
              "  ('charact', 1),\n",
              "  ('cheesi', 1),\n",
              "  ('come', 1),\n",
              "  ('feel', 1),\n",
              "  ('first', 1),\n",
              "  ('fluff', 1),\n",
              "  ('forget', 1),\n",
              "  ('full', 1),\n",
              "  ('go', 4),\n",
              "  ('hear', 1),\n",
              "  ('just', 1),\n",
              "  ('keep', 1),\n",
              "  ('lose', 1),\n",
              "  ('mind', 1),\n",
              "  ('nudg', 1),\n",
              "  ('play', 1),\n",
              "  ('pleasantli', 1),\n",
              "  ('point', 1),\n",
              "  ('pull', 1),\n",
              "  ('rendit', 1),\n",
              "  ('right', 1),\n",
              "  ('son', 1),\n",
              "  ('sure', 1),\n",
              "  ('t', 1),\n",
              "  ('unrealist', 1),\n",
              "  ('version', 1),\n",
              "  ('wake', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FD_7BZQwACU"
      },
      "source": [
        "lda_model_= models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics = 10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ceBj9r0wqoY",
        "outputId": "968f89ac-aa61-4106-ecef-b2a41143ba1b"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(lda_model_.print_topics())\n",
        "doc_lda_ = lda_model_[corpus]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.114*\"go\" + 0.029*\"play\" + 0.029*\"wake\" + 0.029*\"charact\" + 0.029*\"full\" + '\n",
            "  '0.029*\"sure\" + 0.029*\"anguish\" + 0.029*\"come\" + 0.029*\"first\" + '\n",
            "  '0.029*\"forget\"'),\n",
            " (1,\n",
            "  '0.031*\"go\" + 0.031*\"mind\" + 0.031*\"charact\" + 0.031*\"feel\" + '\n",
            "  '0.031*\"pleasantli\" + 0.031*\"anoth\" + 0.031*\"fluff\" + 0.031*\"son\" + '\n",
            "  '0.031*\"t\" + 0.031*\"come\"'),\n",
            " (2,\n",
            "  '0.032*\"go\" + 0.031*\"admit\" + 0.031*\"play\" + 0.031*\"wake\" + 0.031*\"anguish\" '\n",
            "  '+ 0.031*\"first\" + 0.031*\"cheesi\" + 0.031*\"forget\" + 0.031*\"son\" + '\n",
            "  '0.031*\"adult\"'),\n",
            " (3,\n",
            "  '0.031*\"go\" + 0.031*\"unrealist\" + 0.031*\"lose\" + 0.031*\"full\" + '\n",
            "  '0.031*\"anguish\" + 0.031*\"son\" + 0.031*\"point\" + 0.031*\"mind\" + 0.031*\"play\" '\n",
            "  '+ 0.031*\"pull\"'),\n",
            " (4,\n",
            "  '0.031*\"go\" + 0.031*\"right\" + 0.031*\"keep\" + 0.031*\"version\" + '\n",
            "  '0.031*\"forget\" + 0.031*\"son\" + 0.031*\"hear\" + 0.031*\"admit\" + 0.031*\"fluff\" '\n",
            "  '+ 0.031*\"full\"'),\n",
            " (5,\n",
            "  '0.031*\"go\" + 0.031*\"first\" + 0.031*\"t\" + 0.031*\"feel\" + 0.031*\"fluff\" + '\n",
            "  '0.031*\"forget\" + 0.031*\"lose\" + 0.031*\"wake\" + 0.031*\"almost\" + '\n",
            "  '0.031*\"mind\"'),\n",
            " (6,\n",
            "  '0.031*\"go\" + 0.031*\"lose\" + 0.031*\"forget\" + 0.031*\"pull\" + 0.031*\"cheesi\" '\n",
            "  '+ 0.031*\"adult\" + 0.031*\"anoth\" + 0.031*\"pleasantli\" + 0.031*\"fluff\" + '\n",
            "  '0.031*\"mind\"'),\n",
            " (7,\n",
            "  '0.031*\"go\" + 0.031*\"pull\" + 0.031*\"right\" + 0.031*\"nudg\" + 0.031*\"play\" + '\n",
            "  '0.031*\"pleasantli\" + 0.031*\"point\" + 0.031*\"lose\" + 0.031*\"rendit\" + '\n",
            "  '0.031*\"t\"'),\n",
            " (8,\n",
            "  '0.035*\"go\" + 0.031*\"rendit\" + 0.031*\"right\" + 0.031*\"pleasantli\" + '\n",
            "  '0.031*\"point\" + 0.031*\"t\" + 0.031*\"cheesi\" + 0.031*\"unrealist\" + '\n",
            "  '0.031*\"keep\" + 0.031*\"almost\"'),\n",
            " (9,\n",
            "  '0.031*\"go\" + 0.031*\"pull\" + 0.031*\"right\" + 0.031*\"nudg\" + 0.031*\"play\" + '\n",
            "  '0.031*\"pleasantli\" + 0.031*\"point\" + 0.031*\"lose\" + 0.031*\"rendit\" + '\n",
            "  '0.031*\"t\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-55wx0o0LTQ"
      },
      "source": [
        "lsa_model = models.LsiModel(corpus, num_topics = 10, id2word = id2word)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_buMsDGu0QHP",
        "outputId": "0c62dda6-1c26-4db0-bc05-2b90a6e714a6"
      },
      "source": [
        "print(lsa_model.print_topics(num_topics = 10))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.583*\"go\" + 0.146*\"lose\" + 0.146*\"point\" + 0.146*\"right\" + 0.146*\"mind\" + 0.146*\"pleasantli\" + 0.146*\"unrealist\" + 0.146*\"pull\" + 0.146*\"just\" + 0.146*\"t\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "J22QvCwq03zE",
        "outputId": "470b0421-48d6-427b-8bac-3fc9e5afe1a1"
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "print('\\nPerplexity: ', lda_model_.log_perplexity(corpus))\n",
        "coherence_model_lda_ = CoherenceModel(model=lda_model_, text=data_lemmatized_, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda_ = coherence_model_lda_.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda_)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -3.4380914318459057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-20cba78643bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPerplexity: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda_model_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcoherence_model_lda_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_model_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_lemmatized_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcoherence_lda_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoherence_model_lda_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nCoherence Score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoherence_lda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. \n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "vATjQNTY8buA",
        "outputId": "1969633b-0b66-4f0e-f64d-7dae4cf3eb8f"
      },
      "source": [
        "# Write your code here\n",
        "import seaborn as sns\n",
        "print(data['Sentimental Analysis'].value_counts())\n",
        "sns.countplot(data['Sentimental Analysis'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive    61\n",
            "Negative    34\n",
            "Neutral     13\n",
            "Name: Sentimental Analysis, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4e1063810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLwoaZkA1ru6",
        "outputId": "b03811d4-5fe7-461d-eb6c-3def47c42c35"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrhdI3Oh1uZd"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "data['Cleaned Text'] = data['Review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "data['Cleaned Text'] = data['Cleaned Text'].str.replace('[^\\w\\s]','')\n",
        "s = stopwords.words('english')\n",
        "data['Cleaned Text'] = data['Cleaned Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in s))\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgxIUdVo10lX"
      },
      "source": [
        "**Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GgC2OLw14zQ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "Tf_idf_vector = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
        "Tf_idf_vector.fit(data['Review'])\n",
        "x_values_ = Tf_idf_vector.transform(data['Review'])\n",
        "encoder_ = LabelEncoder()\n",
        "y_values_ = encoder_.fit_transform(data['Sentimental Analysis'])"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImM2MN8V2Hc1"
      },
      "source": [
        "I used Tfidf vector for improving the performance for allowing similar meaning terms for same representation, which reduced computional complexity. The model's precision  increases while reducing with overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omwcH-uW2Fm0"
      },
      "source": [
        "\n",
        "from sklearn import model_selection\n",
        "X_train, x_test, y_train, y_test = model_selection.train_test_split(x_values_, y_values_, test_size=0.2)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLd-Zo2M3jj3",
        "outputId": "3be05130-4c33-4c1b-8b0e-bfbc40275161"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import naive_bayes\n",
        "n_b = naive_bayes.MultinomialNB()\n",
        "n_b.fit(X_train, y_train)\n",
        "predicted_nb_ = n_b.predict(x_test)\n",
        "print(\"Accuracy score is {0}\".format(accuracy_score(y_test, predicted_nb_)))\n",
        "report_nb_ = classification_report(y_test, predicted_nb_, output_dict=True)\n",
        "report_nb_"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score is 0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 9},\n",
              " '1': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              " '2': {'f1-score': 0.625,\n",
              "  'precision': 0.45454545454545453,\n",
              "  'recall': 1.0,\n",
              "  'support': 10},\n",
              " 'accuracy': 0.45454545454545453,\n",
              " 'macro avg': {'f1-score': 0.20833333333333334,\n",
              "  'precision': 0.15151515151515152,\n",
              "  'recall': 0.3333333333333333,\n",
              "  'support': 22},\n",
              " 'weighted avg': {'f1-score': 0.2840909090909091,\n",
              "  'precision': 0.20661157024793386,\n",
              "  'recall': 0.45454545454545453,\n",
              "  'support': 22}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqHmO-PN3yTl",
        "outputId": "c3aeade2-e150-456c-e703-e3c514a33ffd"
      },
      "source": [
        "from sklearn import svm\n",
        "svm_model_ = svm.SVC(kernel='linear')\n",
        "svm_model_.fit(X_train, y_train)\n",
        "predicted_model = svm_model_.predict(x_test)\n",
        "print(\"Accuracy score is {0}\".format(accuracy_score(y_test, predicted_model)))\n",
        "report_ = classification_report(y_test, predicted_model, output_dict=True)\n",
        "report_"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score is 0.45454545454545453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 9},\n",
              " '1': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 3},\n",
              " '2': {'f1-score': 0.625,\n",
              "  'precision': 0.45454545454545453,\n",
              "  'recall': 1.0,\n",
              "  'support': 10},\n",
              " 'accuracy': 0.45454545454545453,\n",
              " 'macro avg': {'f1-score': 0.20833333333333334,\n",
              "  'precision': 0.15151515151515152,\n",
              "  'recall': 0.3333333333333333,\n",
              "  'support': 22},\n",
              " 'weighted avg': {'f1-score': 0.2840909090909091,\n",
              "  'precision': 0.20661157024793386,\n",
              "  'recall': 0.45454545454545453,\n",
              "  'support': 22}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download here: https://github.com/unt-iialab/info5731_spring2021/blob/main/assignment/assignment4-question3-data.zip. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "train_data_ = pd.read_csv(\"train.csv\")\n",
        "test_data_ = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "W3F6HLyC4hiA",
        "outputId": "73b89ccd-5fed-4287-c1c2-cbe513783bbc"
      },
      "source": [
        "train_data_.describe()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1201.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1452.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1379.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>56.897260</td>\n",
              "      <td>70.049958</td>\n",
              "      <td>10516.828082</td>\n",
              "      <td>6.099315</td>\n",
              "      <td>5.575342</td>\n",
              "      <td>1971.267808</td>\n",
              "      <td>1984.865753</td>\n",
              "      <td>103.685262</td>\n",
              "      <td>443.639726</td>\n",
              "      <td>46.549315</td>\n",
              "      <td>567.240411</td>\n",
              "      <td>1057.429452</td>\n",
              "      <td>1162.626712</td>\n",
              "      <td>346.992466</td>\n",
              "      <td>5.844521</td>\n",
              "      <td>1515.463699</td>\n",
              "      <td>0.425342</td>\n",
              "      <td>0.057534</td>\n",
              "      <td>1.565068</td>\n",
              "      <td>0.382877</td>\n",
              "      <td>2.866438</td>\n",
              "      <td>1.046575</td>\n",
              "      <td>6.517808</td>\n",
              "      <td>0.613014</td>\n",
              "      <td>1978.506164</td>\n",
              "      <td>1.767123</td>\n",
              "      <td>472.980137</td>\n",
              "      <td>94.244521</td>\n",
              "      <td>46.660274</td>\n",
              "      <td>21.954110</td>\n",
              "      <td>3.409589</td>\n",
              "      <td>15.060959</td>\n",
              "      <td>2.758904</td>\n",
              "      <td>43.489041</td>\n",
              "      <td>6.321918</td>\n",
              "      <td>2007.815753</td>\n",
              "      <td>180921.195890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>421.610009</td>\n",
              "      <td>42.300571</td>\n",
              "      <td>24.284752</td>\n",
              "      <td>9981.264932</td>\n",
              "      <td>1.382997</td>\n",
              "      <td>1.112799</td>\n",
              "      <td>30.202904</td>\n",
              "      <td>20.645407</td>\n",
              "      <td>181.066207</td>\n",
              "      <td>456.098091</td>\n",
              "      <td>161.319273</td>\n",
              "      <td>441.866955</td>\n",
              "      <td>438.705324</td>\n",
              "      <td>386.587738</td>\n",
              "      <td>436.528436</td>\n",
              "      <td>48.623081</td>\n",
              "      <td>525.480383</td>\n",
              "      <td>0.518911</td>\n",
              "      <td>0.238753</td>\n",
              "      <td>0.550916</td>\n",
              "      <td>0.502885</td>\n",
              "      <td>0.815778</td>\n",
              "      <td>0.220338</td>\n",
              "      <td>1.625393</td>\n",
              "      <td>0.644666</td>\n",
              "      <td>24.689725</td>\n",
              "      <td>0.747315</td>\n",
              "      <td>213.804841</td>\n",
              "      <td>125.338794</td>\n",
              "      <td>66.256028</td>\n",
              "      <td>61.119149</td>\n",
              "      <td>29.317331</td>\n",
              "      <td>55.757415</td>\n",
              "      <td>40.177307</td>\n",
              "      <td>496.123024</td>\n",
              "      <td>2.703626</td>\n",
              "      <td>1.328095</td>\n",
              "      <td>79442.502883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1900.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>34900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>365.750000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>7553.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1967.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>795.750000</td>\n",
              "      <td>882.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1129.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1961.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>334.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>129975.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>730.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>9478.500000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>383.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>477.500000</td>\n",
              "      <td>991.500000</td>\n",
              "      <td>1087.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1464.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1980.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>163000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1095.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>11601.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>712.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>808.000000</td>\n",
              "      <td>1298.250000</td>\n",
              "      <td>1391.250000</td>\n",
              "      <td>728.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1776.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2002.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2009.000000</td>\n",
              "      <td>214000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1460.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>215245.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>1600.000000</td>\n",
              "      <td>5644.000000</td>\n",
              "      <td>1474.000000</td>\n",
              "      <td>2336.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>4692.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>572.000000</td>\n",
              "      <td>5642.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1418.000000</td>\n",
              "      <td>857.000000</td>\n",
              "      <td>547.000000</td>\n",
              "      <td>552.000000</td>\n",
              "      <td>508.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>738.000000</td>\n",
              "      <td>15500.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Id   MSSubClass  ...       YrSold      SalePrice\n",
              "count  1460.000000  1460.000000  ...  1460.000000    1460.000000\n",
              "mean    730.500000    56.897260  ...  2007.815753  180921.195890\n",
              "std     421.610009    42.300571  ...     1.328095   79442.502883\n",
              "min       1.000000    20.000000  ...  2006.000000   34900.000000\n",
              "25%     365.750000    20.000000  ...  2007.000000  129975.000000\n",
              "50%     730.500000    50.000000  ...  2008.000000  163000.000000\n",
              "75%    1095.250000    70.000000  ...  2009.000000  214000.000000\n",
              "max    1460.000000   190.000000  ...  2010.000000  755000.000000\n",
              "\n",
              "[8 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBHJC6G4meB",
        "outputId": "4a822a65-e9df-46e4-8d29-ba11278a839e"
      },
      "source": [
        "print(train_data_.isnull().sum())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      259\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-nSKDub4pXx",
        "outputId": "bfcb353f-bdea-4550-84f0-30a35bab00e5"
      },
      "source": [
        "print(test_data_.isnull().sum())"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           4\n",
            "LotFrontage      227\n",
            "LotArea            0\n",
            "                ... \n",
            "MiscVal            0\n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           1\n",
            "SaleCondition      0\n",
            "Length: 80, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MmmoKIg4vds"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    }
  ]
}